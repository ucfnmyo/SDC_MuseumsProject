{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Historical Data from Darwin API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising endpoint\n",
    "\n",
    "#Service Details endpoint\n",
    "SD_endpoint = \"https://hsp-prod.rockshore.net/api/v1/serviceDetails\"\n",
    "\n",
    "#Service Metrics endpoint\n",
    "SM_endpoint = \"https://hsp-prod.rockshore.net/api/v1/serviceMetrics\"\n",
    "\n",
    "#Setting Headers and authorisation\n",
    "header = {\"Content-Type\" : \"application/json\"};\n",
    "auth = (\"mohammadyounes08@gmail.com\",\"CASAEliteSquad2019$$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS HAS NOT SUCCESSFULLY GOTTEN DATA FROM THE API YET\n",
    "\n",
    "# usually returns <Response [502]> bad gateway. \n",
    "#I've also seen [400] bad request, and [200] ok, but without any data\n",
    "\n",
    "# test api connection here\n",
    "\n",
    "# The request requires an origin station (stn1) and a destination station (stn2). \n",
    "# The time is put from 0000 to 2359 to imply the full day.\n",
    "# Make sure to change the dates to get the desired data\n",
    "\n",
    "data = {\n",
    "    'url': SM_endpoint, \n",
    "    \"from_loc\":\"VIC\",\n",
    "    \"to_loc\":\"BMS\",\n",
    "    \"from_time\":\"0000\",\n",
    "    \"to_time\":\"2359\",\n",
    "    \"from_date\":\"2018-02-06\",\n",
    "    \"to_date\":\"2018-02-09\",\n",
    "    \"days\":\"WEEKDAY\"\n",
    "    }\n",
    "\n",
    "test_request = requests.post(SM_endpoint, headers = header, auth = auth, data = json.dumps(data))\n",
    "print(\"status: \", test_request)  \n",
    "\n",
    "info_from_api = json_normalize(test_request.json()['Services']) \n",
    "print(\"info returned: \", info_from_api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Metrics - Historical Data Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting Headers and authorisation\n",
    "header = {\"Content-Type\" : \"application/json\"};\n",
    "auth = (\"mohammadyounes08@gmail.com\",\"CASAEliteSquad2019$$\");\n",
    "\n",
    "#Empty Dataframe to append the data to\n",
    "Services = pd.DataFrame(columns = [\"Metrics\",\"serviceAttributesMetrics.destination_location\",\"serviceAttributesMetrics.gbtt_pta\",\"serviceAttributesMetrics.gbtt_ptd\",\"serviceAttributesMetrics.matched_services\",\"serviceAttributesMetrics.origin_location\",\"serviceAttributesMetrics.rids\",\"serviceAttributesMetrics.toc_code\"])\n",
    "\n",
    "#csv file of station codes to loop over\n",
    "StationCodes = pd.read_csv('station_codes.csv')\n",
    "\n",
    "for stn1 in StationCodes['CRS Code']:\n",
    "    \n",
    "    for stn2 in StationCodes['CRS Code']:\n",
    "        \n",
    "      \n",
    "        if(stn1 != stn2):\n",
    "            \n",
    "            data = {'url': SM_endpoint, \n",
    "                \n",
    "                #The request requires an origin station (stn1) and a destination station (stn 2). The time is put from 0000 to 2359 to imply the full day.\n",
    "                #Make sure to change the dates to get the desired data\n",
    "                \"from_loc\": stn1,\n",
    "                \"to_loc\": stn2,\n",
    "                \"from_time\":\"0000\",\n",
    "                \"to_time\":\"2359\",\n",
    "                \"from_date\":\"2016-01-01\",\n",
    "                \"to_date\":\"2016-01-03\",\n",
    "                \"days\":\"WEEKDAY\"\n",
    "        \n",
    "            }\n",
    "            \n",
    "            try: \n",
    "                SM_requests = requests.post(SM_endpoint, headers = header, auth = auth, data = json.dumps(data))\n",
    "            \n",
    "                Data = json_normalize(SM_requests.json()['Services']) \n",
    "            \n",
    "                Services = Services.append(Data, ignore_index = True)\n",
    "            \n",
    "                print(stn1, stn2)\n",
    "                print(\"status: \", SM_requests)\n",
    "                print(\"data: \", Data)\n",
    "            except: \n",
    "                \n",
    "                print(stn1,stn2)\n",
    "                print(\"possibly no trains between these stations on this day\")\n",
    "                print(\"api returned: \", SM_requests)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Details - Historical Data Service Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Request details - header and auth\n",
    "\n",
    "header = {\"Content-Type\" : \"application/json\"};\n",
    "auth = (\"mohammadyounes08@gmail.com\",\"CASAEliteSquad2019$$\");\n",
    "\n",
    "#The RIDs obtained from the service metrics API contain the date in the first 8 digits.\n",
    "#for example 201607294212242 would indicate 29/07/2016\n",
    "\n",
    "#Empty dataframe to append data from the requests\n",
    "ServiceDetails = pd.DataFrame(columns = [\"date_of_service\",\"locations\",\"rid\", \"toc_code\"])\n",
    "\n",
    "#This for loop iterates over the rids obtained from the Service metrics request to obtain the details on each train.\n",
    "#The returned information will include data on schedules arrivals and actual time of arrival\n",
    "\n",
    "for rid in Services['serviceAttributesMetrics.rids']:\n",
    "    \n",
    "    data = {'url': SD_endpoint, \"Content-Length\":1000, \"rid\" : rid[0]}\n",
    "    \n",
    "    SD_requests = requests.post(SD_endpoint, headers= header, auth=auth, data = json.dumps(data))\n",
    "\n",
    "    SD_PD = json_normalize(SD_requests.json()['serviceAttributesDetails'])\n",
    "    \n",
    "    ServiceDetails = ServiceDetails.append(SD_PD, ignore_index= True)\n",
    "    # print(rid[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ServiceDetails.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "station_data = pd.read_csv('station_codes.csv')\n",
    "station_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the server\n",
    "#change username twice and password once. \n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://USERNAME:PASSWORD@dev.spatialdatacapture.org:3306/USERNAME')\n",
    "\n",
    "conn = engine.raw_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get database info\n",
    "\n",
    "table_names = engine.table_names()\n",
    "\n",
    "print(table_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test select\n",
    "\n",
    "test_data = pd.read_sql('SELECT * FROM cities', conn)\n",
    "\n",
    "\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then upload the data to the db\n",
    "\n",
    "station_data.to_sql(name = 'stations', con=engine , if_exists = 'fail')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# and check if it's there by selecting\n",
    "\n",
    "test_2 = pd.read_sql('SELECT * FROM stations', conn)\n",
    "\n",
    "test_2.head(2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
